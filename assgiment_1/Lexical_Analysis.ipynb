{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import json\n",
    "import graphviz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_regex(regex):\n",
    "    \"\"\"\n",
    "    parameters :\n",
    "    regex : check this regex if it valid or not\n",
    "    return : \n",
    "    bool : True if it valid, and False if it invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        re.compile(regex)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def add_concat(regex, operators):\n",
    "    \"\"\"\n",
    "    add concatenate operator to given regex\n",
    "    parameters :\n",
    "    regex : valid regex\n",
    "    operators : valid operators in regex \n",
    "    return : \n",
    "    regex_with_concat : valid regex with concatenate operator\n",
    "    \"\"\"\n",
    "    regex_with_concat = []\n",
    "    i = 0\n",
    "    while i < len(regex) - 1:\n",
    "        regex_with_concat.append(regex[i])\n",
    "        if regex[i] not in operators:\n",
    "            if regex[i + 1] not in operators or regex[i + 1] == '(' or regex[i + 1] == '[':\n",
    "                regex_with_concat += '.'\n",
    "        if (regex[i] == ')' or regex[i] == ']') and (regex[i + 1] == '(' or regex[i + 1] == '['):\n",
    "            regex_with_concat += '.'\n",
    "        if (regex[i] == '*' or regex[i] == '+' or regex[i] == '?') and (regex[i + 1] == '(' or regex[i + 1] == '['):\n",
    "            regex_with_concat += '.'\n",
    "        if (regex[i] == '*' or regex[i] == '+' or regex[i] == '?') and regex[i + 1] not in operators:\n",
    "            regex_with_concat += '.'\n",
    "        if (regex[i] == ')' or regex[i] == ']') and regex[i + 1] not in operators:\n",
    "            regex_with_concat += '.'\n",
    "        if regex[i] == '[':\n",
    "            while regex[i+1] != ']':\n",
    "                i += 1\n",
    "                regex_with_concat.append(regex[i])\n",
    "        i += 1\n",
    "\n",
    "    regex_with_concat += regex[len(regex) - 1]\n",
    "    return regex_with_concat\n",
    "\n",
    "def comp_precedence(a, b):\n",
    "    \"\"\"\n",
    "    parameters :\n",
    "    a : first operator\n",
    "    b : second operator\n",
    "    return :\n",
    "    bool : True if a has high precedence false otherwise\n",
    "    \"\"\"\n",
    "    p = [\"|\", \".\", \"-\", \"*\", \"+\", \"?\"]\n",
    "    return p.index(a) > p.index(b)\n",
    "\n",
    "def creat_postfix_regex(regex, operators):\n",
    "    \"\"\"\n",
    "    apply Shunting-Yard algorithm to creat postfix regex\n",
    "    parameters :\n",
    "    regex : valid regex with concatenate operator\n",
    "    operators : valid operators in regex \n",
    "    return : \n",
    "    postfix_regex : list of char that represente postfix regex \n",
    "    \"\"\"\n",
    "    postfix_regex = \"\"\n",
    "    operator_stack = []\n",
    "\n",
    "    for c in regex:\n",
    "        if c not in operators or c == \"*\" or c == \"+\" or c == \"?\" or c == \"[\" or c == \"]\":\n",
    "            postfix_regex += c\n",
    "        elif c == \")\": # or c == \"]\"\n",
    "            while len(operator_stack) > 0 and operator_stack[-1] != \"(\" and operator_stack[-1] != \"[\":\n",
    "                postfix_regex += operator_stack.pop()\n",
    "            operator_stack.pop()\n",
    "        elif c == \"[\" or c == \"(\" or len(operator_stack) == 0 or operator_stack[-1] == \"(\" or operator_stack[-1] == \"[\" or comp_precedence(c, operator_stack[-1]):\n",
    "            operator_stack.append(c)\n",
    "        else:\n",
    "            while len(operator_stack) > 0 and operator_stack[-1] != \"(\" and operator_stack[-1] != \"[\" and not comp_precedence(c, operator_stack[-1]):\n",
    "                postfix_regex += operator_stack.pop()\n",
    "            operator_stack.append(c)\n",
    "\n",
    "    while len(operator_stack) > 0:\n",
    "        postfix_regex += operator_stack.pop()\n",
    "\n",
    "    return postfix_regex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class state:\n",
    "    def __init__(self, id=\"\", is_start=False, is_terminal=False, next_states={}):\n",
    "        self.id = id\n",
    "        self.is_start = is_start\n",
    "        self.is_terminal = is_terminal\n",
    "        self.next_states = next_states\n",
    "    def print_state(self):\n",
    "        print(\"state \", self.id)\n",
    "        for out in self.next_states:\n",
    "            print(\"on \", out, \"go to\", self.next_states[out])\n",
    "        if self.is_start:\n",
    "            print(\"state is a start state\")\n",
    "        if self.is_terminal:\n",
    "            print(\"state is a terminal state\")\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_nfa(postfix_regex, operators):\n",
    "    \"\"\"\n",
    "    convert postfix regex to finite state machine using Thompson's Construction algorithm for NFAs\n",
    "    parameters :\n",
    "    postfix_regex : postfix regex (output from Shunting-Yard algorithm)\n",
    "    operators : valid operators in regex \n",
    "    return : \n",
    "    states : array holds all states that formulate NFA \n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    states = []\n",
    "    states_stack =[]\n",
    "    while i < len(postfix_regex):\n",
    "        if postfix_regex[i] not in operators:\n",
    "            s1 = state(str(i) + str(0), True, False, {postfix_regex[i] : str(i) + str(1)})\n",
    "            s2 = state(str(i) + str(1), False, True, {})\n",
    "        else:\n",
    "            if postfix_regex[i] == '[':\n",
    "                next_states = {}\n",
    "                state_id = i\n",
    "                if len(postfix_regex) > i+4 and postfix_regex[i+4] == '-':\n",
    "                    for j in range(ord(postfix_regex[i+1]), ord(postfix_regex[i+2]) + 1):\n",
    "                        next_states[chr(j)] = str(state_id) + str(1)\n",
    "                    i += 4 \n",
    "                else:\n",
    "                    while postfix_regex[i+1] != ']':\n",
    "                        i += 1\n",
    "                        next_states[postfix_regex[i]] = str(state_id) + str(1)\n",
    "                    i += 1\n",
    "                s1 = state(str(state_id) + str(0), True, False, next_states)\n",
    "                s2 = state(str(state_id) + str(1), False, True, {})\n",
    "\n",
    "            if postfix_regex[i] == '|':\n",
    "                second_nfa_state = states_stack.pop()\n",
    "                first_nfa_state = states_stack.pop()\n",
    "                s1 = state(str(i) + str(0), True, False, {\"epsilon\" : [first_nfa_state[0].id, second_nfa_state[0].id]})\n",
    "                s2 = state(str(i) + str(1), False, True, {})\n",
    "                # add epsilon\n",
    "                if \"epsilon\" in first_nfa_state[1].next_states:\n",
    "                    first_nfa_state[1].next_states[\"epsilon\"].append(s2.id)\n",
    "                else:\n",
    "                    first_nfa_state[1].next_states[\"epsilon\"] = [s2.id]\n",
    "                if \"epsilon\" in second_nfa_state[1].next_states:\n",
    "                    second_nfa_state[1].next_states[\"epsilon\"].append(s2.id)\n",
    "                else:\n",
    "                    second_nfa_state[1].next_states[\"epsilon\"] = [s2.id]\n",
    "                # make it non trminal\n",
    "                first_nfa_state[1].is_terminal = False\n",
    "                second_nfa_state[1].is_terminal = False\n",
    "\n",
    "                # make it non start state\n",
    "                first_nfa_state[0].is_start = False\n",
    "                second_nfa_state[0].is_start = False\n",
    "\n",
    "            if postfix_regex[i] == '.':\n",
    "                second_nfa_state = states_stack.pop()\n",
    "                first_nfa_state = states_stack.pop()\n",
    "                s1 = state(str(i) + str(0), True, False, {\"epsilon\" : [first_nfa_state[0].id]})\n",
    "                s2 = state(str(i) + str(1), False, True, {})\n",
    "                \n",
    "                # add epsilon\n",
    "                if \"epsilon\" in first_nfa_state[1].next_states:\n",
    "                    first_nfa_state[1].next_states[\"epsilon\"].append(second_nfa_state[0].id)\n",
    "                else:\n",
    "                    first_nfa_state[1].next_states[\"epsilon\"] = [second_nfa_state[0].id]\n",
    "                if \"epsilon\" in second_nfa_state[1].next_states:\n",
    "                    second_nfa_state[1].next_states[\"epsilon\"].append(s2.id)\n",
    "                else:\n",
    "                    second_nfa_state[1].next_states[\"epsilon\"] = [s2.id]\n",
    "                \n",
    "                # make it non trminal\n",
    "                first_nfa_state[1].is_terminal = False\n",
    "                second_nfa_state[1].is_terminal = False\n",
    "                \n",
    "                # make it non start state\n",
    "                first_nfa_state[0].is_start = False\n",
    "                second_nfa_state[0].is_start = False\n",
    "\n",
    "            if postfix_regex[i] == '*':\n",
    "                nfa_state = states_stack.pop()\n",
    "                s1 = state(str(i) + str(0), True, False, {\"epsilon\" : [nfa_state[0].id, str(i) + str(1)]})\n",
    "                s2 = state(str(i) + str(1), False, True, {})\n",
    "                \n",
    "                # add epsilon\n",
    "                if \"epsilon\" in nfa_state[1].next_states:\n",
    "                    nfa_state[1].next_states[\"epsilon\"].append(nfa_state[0].id)\n",
    "                else:\n",
    "                    nfa_state[1].next_states[\"epsilon\"] = [nfa_state[0].id]\n",
    "                nfa_state[1].next_states[\"epsilon\"].append(s2.id)\n",
    "                \n",
    "                # make it non trminal\n",
    "                nfa_state[1].is_terminal = False\n",
    "\n",
    "                # make it non start state\n",
    "                nfa_state[0].is_start = False\n",
    "\n",
    "            if postfix_regex[i] == '+':\n",
    "                nfa_state = states_stack.pop()\n",
    "                s1 = state(str(i) + str(0), True, False, {\"epsilon\" : [nfa_state[0].id]})\n",
    "                s2 = state(str(i) + str(1), False, True, {})\n",
    "                \n",
    "                # add epsilon\n",
    "                if \"epsilon\" in nfa_state[1].next_states:\n",
    "                    nfa_state[1].next_states[\"epsilon\"].append(nfa_state[0].id)\n",
    "                else:\n",
    "                    nfa_state[1].next_states[\"epsilon\"] = [nfa_state[0].id]\n",
    "                nfa_state[1].next_states[\"epsilon\"].append(s2.id)\n",
    "                \n",
    "                # make it non trminal\n",
    "                nfa_state[1].is_terminal = False\n",
    "\n",
    "                # make it non start state\n",
    "                nfa_state[0].is_start = False\n",
    "            \n",
    "            if postfix_regex[i] == '?':\n",
    "                nfa_state = states_stack.pop()\n",
    "                s1 = state(str(i) + str(0), True, False, {\"epsilon\" : [nfa_state[0].id, str(i) + str(1)]})\n",
    "                s2 = state(str(i) + str(1), False, True, {})\n",
    "                \n",
    "                # add epsilon\n",
    "                if \"epsilon\" in nfa_state[1].next_states:\n",
    "                    nfa_state[1].next_states[\"epsilon\"].append(s2.id)\n",
    "                else:\n",
    "                    nfa_state[1].next_states[\"epsilon\"] = [s2.id]\n",
    "                \n",
    "                # make it non trminal\n",
    "                nfa_state[1].is_terminal = False\n",
    "\n",
    "                # make it non start state\n",
    "                nfa_state[0].is_start = False\n",
    "        \n",
    "        states_stack.append((s1, s2))\n",
    "        states.append(s1)\n",
    "        states.append(s2)\n",
    "        i += 1\n",
    "    return states\n",
    "\n",
    "def write_nfa_states_json(states):\n",
    "    \"\"\"\n",
    "    write all NFA states in json file and draw a graph for all states\n",
    "    parameters :\n",
    "    states : array holds all states that formulate NFA \n",
    "    return :\n",
    "    dict_states : dictionary key is states id and value is states\n",
    "    starting_state : starting state in nfa\n",
    "    \"\"\"\n",
    "    dot = graphviz.Digraph()\n",
    "    data = {\n",
    "    \"startingState\": \"bla\",\n",
    "    }\n",
    "\n",
    "    starting_state = None \n",
    "    dict_states = {}\n",
    "    for state in states:\n",
    "        dict_states[state.id] = state\n",
    "        if state.is_start and state.is_terminal:\n",
    "            dot.node(state.id, shape= \"doublecircle\")\n",
    "            data[\"startingState\"] = state.id\n",
    "            starting_state = state.id\n",
    "        elif state.is_start:\n",
    "            data[\"startingState\"] = state.id\n",
    "            starting_state = state.id\n",
    "            dot.node(state.id)\n",
    "        elif state.is_terminal:\n",
    "            dot.node(state.id, shape= \"doublecircle\")\n",
    "        else:\n",
    "            dot.node(state.id)\n",
    "        \n",
    "        if state.is_start:\n",
    "            data[\"startingState\"] = state.id\n",
    "            starting_state = state.id\n",
    "        state_data = {\n",
    "            \"isTerminatingState\": state.is_terminal\n",
    "        }\n",
    "        for next_state in state.next_states:\n",
    "            state_data[\"inputCharacter\" + next_state.upper()] = state.next_states[next_state]\n",
    "            if isinstance(state.next_states[next_state], list):\n",
    "                for edge in state.next_states[next_state]:\n",
    "                    dot.edge(state.id, edge, next_state)\n",
    "            else:\n",
    "                dot.edge(state.id, state.next_states[next_state], next_state)\n",
    "        data[\"state\" + state.id] = state_data\n",
    "\n",
    "    with open(\"NFA.json\", \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "    \n",
    "    dot.render('NFA')\n",
    "    return dict_states, starting_state\n",
    "\n",
    "def re_to_nfa(regex):\n",
    "    \"\"\"\n",
    "    convert regex to NFA\n",
    "    parameters :\n",
    "    regex : input regex \n",
    "    return :\n",
    "    dict_states : dictionary key is states id and value is states\n",
    "    starting_state : starting state in nfa\n",
    "    \"\"\"\n",
    "    if not is_valid_regex(regex):\n",
    "        return \"error, invalid regex\"\n",
    "    operators = ['|', '+', '*', '?', '-', '(', ')', '[', ']', '.']\n",
    "    regex_with_concat = add_concat(regex, operators)\n",
    "    postfix_regex = creat_postfix_regex(regex_with_concat, operators)\n",
    "    states = creat_nfa(postfix_regex, operators)\n",
    "    dict_states, starting_state = write_nfa_states_json(states)\n",
    "    return dict_states, starting_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nfa_states_json(filename = \"NFA\"):\n",
    "    \"\"\"\n",
    "    load all NFA states from json file \n",
    "    parameters :\n",
    "    filename : json file name to be loaded\n",
    "    return :\n",
    "    dict_states : dictionary key is states id and value is states\n",
    "    starting_state : starting state in nfa\n",
    "    \"\"\"\n",
    "    file = open(filename + '.json')\n",
    "    data = json.load(file)\n",
    "    \n",
    "    dict_states = {}\n",
    "    for i in data:\n",
    "        if i == \"startingState\":\n",
    "            starting_state = data[\"startingState\"]\n",
    "        else:\n",
    "            id = i.replace(\"state\",'')\n",
    "            is_terminal = data[i][\"isTerminatingState\"]\n",
    "            next_states = {}\n",
    "            for j in data[i]:\n",
    "                if \"inputCharacter\" in j:\n",
    "                    action = j.replace(\"inputCharacter\", '')\n",
    "                    action = action.lower()\n",
    "                    next_states[action] = data[i][j]\n",
    "            s = state(id, id == starting_state, is_terminal, next_states)\n",
    "            dict_states[id] = s\n",
    "        \n",
    "    file.close()\n",
    "    return dict_states, starting_state\n",
    "\n",
    "def epsilon_closure(state, nfa_states):\n",
    "    \"\"\"\n",
    "    loop over epsilon paths from given state to get epsilon closure\n",
    "    parameters :\n",
    "    state : given state id to begin with this state\n",
    "    nfa_states : dictionary of all nfa states; key : state id, value : state\n",
    "    return :\n",
    "    state_with_epsilon : a new state that holds all states id that presents the epsilon closure\n",
    "    is_terminal : result from oring is_terminal to each state in new state\n",
    "    \"\"\"\n",
    "    visited_states = []\n",
    "    unvisited_states = [state]\n",
    "    state_with_epsilon = []\n",
    "    is_terminal = False\n",
    "    # epsilon closure on start state\n",
    "    while len(unvisited_states) > 0:\n",
    "        current_state = nfa_states[unvisited_states[0]]\n",
    "        visited_states.append(unvisited_states[0])\n",
    "        unvisited_states = unvisited_states[1:]\n",
    "        is_terminal = is_terminal or current_state.is_terminal\n",
    "        state_with_epsilon.append(current_state.id)\n",
    "        for next_state in current_state.next_states:\n",
    "            if next_state == \"epsilon\":\n",
    "                for dest_state in current_state.next_states[next_state]:\n",
    "                    if dest_state not in visited_states:\n",
    "                        unvisited_states.append(dest_state)\n",
    "\n",
    "\n",
    "    return state_with_epsilon, is_terminal\n",
    "\n",
    "def nfa_to_dfa(nfa_states, starting_state):\n",
    "    \"\"\"\n",
    "    parameters :\n",
    "    nfa_states : dictionary of all nfa states; key : state id, value : state\n",
    "    starting_state : start state id in NFA state machine\n",
    "    return :\n",
    "    dfa_states_dict : dictionary that represent all DFA states; key : id, value : state\n",
    "    set_of_actions : set of all different actions from state to other\n",
    "    \"\"\"\n",
    "    set_of_actions = set()\n",
    "    for nfa_state in nfa_states:\n",
    "        for next_state in nfa_states[nfa_state].next_states:\n",
    "            set_of_actions.add(next_state)\n",
    "    set_of_actions.remove('epsilon')\n",
    "\n",
    "    state_index = 0\n",
    "    # epsilon closure on start state\n",
    "    state_with_epsilon, is_terminal = epsilon_closure(starting_state, nfa_states)\n",
    "    starting_state_with_epsilon = set(state_with_epsilon)\n",
    "    s = state(str(state_index), True, is_terminal, {})\n",
    "\n",
    "    dfa_states_ids = [starting_state_with_epsilon]\n",
    "    dfa_states_dict = {state_index : s}\n",
    "    queue = [starting_state_with_epsilon]\n",
    "    while len(queue) > 0:\n",
    "        current_dfa_state = queue.pop(0)\n",
    "        for action in set_of_actions:\n",
    "            new_state = set()\n",
    "            new_is_terminal = False\n",
    "            for nfa_state in current_dfa_state:\n",
    "                if action in nfa_states[nfa_state].next_states:\n",
    "                    new_state.add(nfa_states[nfa_state].next_states[action])\n",
    "                    state_with_epsilon, is_terminal = epsilon_closure(nfa_states[nfa_state].next_states[action], nfa_states)\n",
    "                    new_is_terminal = new_is_terminal or is_terminal\n",
    "                    new_state = set(state_with_epsilon).union(new_state)\n",
    "                    # new_state = set(new_state)\n",
    "\n",
    "            if len(new_state) > 0 and new_state not in dfa_states_ids:\n",
    "                dfa_states_ids.append(new_state)\n",
    "                queue.append(new_state)\n",
    "                s = state(str(dfa_states_ids.index(new_state)), False, new_is_terminal, {})\n",
    "                dfa_states_dict[dfa_states_ids.index(new_state)] = s\n",
    "            \n",
    "            if len(new_state) > 0:\n",
    "                dfa_states_dict[state_index].next_states[action] = str(dfa_states_ids.index(new_state))\n",
    "        state_index += 1\n",
    "\n",
    "    return dfa_states_dict, set_of_actions\n",
    "\n",
    "def write_dfa_states_json(states, is_minimized):\n",
    "    \"\"\"\n",
    "    write all DFA states in json file\n",
    "    parameters :\n",
    "    states : array holds all states that formulate DFA \n",
    "    is_minimized : flag if the dfa is minimized : True\n",
    "    \"\"\"\n",
    "    dot = graphviz.Digraph()\n",
    "    data = {\n",
    "    \"startingState\": \"bla\",\n",
    "    }\n",
    "\n",
    "    for state in states:\n",
    "        if states[state].is_start and states[state].is_terminal:\n",
    "            dot.node(states[state].id, \"start\", shape= \"doublecircle\")\n",
    "            data[\"startingState\"] = states[state].id\n",
    "        elif states[state].is_start:\n",
    "            data[\"startingState\"] = states[state].id\n",
    "            dot.node(states[state].id, \"start\")\n",
    "        elif states[state].is_terminal:\n",
    "            dot.node(states[state].id, shape= \"doublecircle\")\n",
    "        else:\n",
    "            dot.node(states[state].id)\n",
    "\n",
    "        state_data = {\n",
    "            \"isTerminatingState\": states[state].is_terminal\n",
    "        }\n",
    "        for next_state in states[state].next_states:\n",
    "            state_data[\"inputCharacter\" + next_state.upper()] = states[state].next_states[next_state]\n",
    "            if isinstance(states[state].next_states[next_state], list):\n",
    "                for edge in state.next_states[next_state]:\n",
    "                    dot.edge(states[state].id, edge, next_state)\n",
    "            else:\n",
    "                dot.edge(states[state].id, states[state].next_states[next_state], next_state)\n",
    "        data[\"state\" + states[state].id] = state_data\n",
    "    \n",
    "    if is_minimized:\n",
    "        file_name = \"min_DFA.json\"\n",
    "        dot.render('min_DFA')\n",
    "    else:\n",
    "        file_name = \"DFA.json\"\n",
    "        dot.render('DFA')\n",
    "\n",
    "    with open(file_name, \"w\") as f:\n",
    "        json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_dfa(dfa_states, set_of_actions):\n",
    "    \"\"\"\n",
    "    apply minimized algorithm to reduce number of DFA states\n",
    "    parameters :\n",
    "    dfa_states : dictionary of all DFA states; key : state id, value : state\n",
    "    set_of_actions : set of all different actions from state to other\n",
    "    return :\n",
    "    minimized_states_dict : dictionary of all minimized DFA states; key : state id, value : state\n",
    "    \"\"\"\n",
    "    terminal_state = []\n",
    "    nonterminal_state = []\n",
    "    for dfa_state in dfa_states:\n",
    "        if dfa_states[dfa_state].is_terminal:\n",
    "            terminal_state.append(dfa_states[dfa_state].id)\n",
    "        else:\n",
    "            nonterminal_state.append(dfa_states[dfa_state].id)\n",
    "    \n",
    "    if len(terminal_state) == 0:\n",
    "        minimized_states = [nonterminal_state]\n",
    "    elif len(nonterminal_state) == 0:\n",
    "        minimized_states = [terminal_state]\n",
    "    else:\n",
    "        minimized_states = [terminal_state, nonterminal_state]\n",
    "    is_updated = True\n",
    "    while is_updated:\n",
    "        is_updated = False\n",
    "        new_minimized_states = copy.deepcopy(minimized_states)\n",
    "        for i in range(len(minimized_states)):\n",
    "            if len(minimized_states[i]) != 1:\n",
    "                for action in set_of_actions:\n",
    "                    destination_state = None\n",
    "                    # this loop determine which state should be destination state\n",
    "                    for minimized_state in minimized_states[i]:\n",
    "                        if action in dfa_states[int(minimized_state)].next_states:\n",
    "                            destination_state = dfa_states[int(minimized_state)].next_states[action]\n",
    "                            break\n",
    "                    if destination_state:\n",
    "                        for i in range(len(minimized_states)):\n",
    "                            if destination_state in minimized_states[i]:\n",
    "                                destination_state_index = i\n",
    "                                break\n",
    "                        out_states = []\n",
    "                        for dfa_state in minimized_states[i]:\n",
    "                            if action not in dfa_states[int(dfa_state)].next_states or dfa_states[int(dfa_state)].next_states[action] not in minimized_states[destination_state_index]:\n",
    "                                out_states.append(dfa_state)\n",
    "                                new_minimized_states[i].remove(dfa_state)\n",
    "                                is_updated = True\n",
    "                    if is_updated:\n",
    "                        new_minimized_states.append(out_states)\n",
    "                        break\n",
    "        minimized_states = new_minimized_states\n",
    "\n",
    "    minimized_states_dict = {}\n",
    "    ids = []\n",
    "    for minimized_state in minimized_states:\n",
    "        ids.append(''.join(set(minimized_state)))\n",
    "\n",
    "    for minimized_state in minimized_states:\n",
    "        id = \"\"\n",
    "        is_terminal = False\n",
    "        is_start = False\n",
    "        next_states = {}\n",
    "        for one_state in set(minimized_state):\n",
    "            id += dfa_states[int(one_state)].id\n",
    "            is_terminal = is_terminal or dfa_states[int(one_state)].is_terminal\n",
    "            is_start = is_start or dfa_states[int(one_state)].is_start\n",
    "            for next_state in dfa_states[int(one_state)].next_states:\n",
    "                if dfa_states[int(one_state)].next_states[next_state] in ids:\n",
    "                    next_states[next_state] = dfa_states[int(one_state)].next_states[next_state]\n",
    "                else:\n",
    "                    for one_id in ids:\n",
    "                        if dfa_states[int(one_state)].next_states[next_state] in one_id:\n",
    "                            next_states[next_state] = one_id\n",
    "                            break\n",
    "        minimized_states_dict[id] = state(id, is_start, is_terminal, next_states)\n",
    "    return minimized_states_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try the algorithm :) \n",
    "##### enter any regex to convert it to minimized DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfa_dict_states, starting_state = re_to_nfa(\"ab(b|c)*d+\") \n",
    "# nfa_dict_states, starting_state = load_nfa_states_json(\"NFA\")\n",
    "dfa_states, set_of_actions = nfa_to_dfa(nfa_dict_states, starting_state)\n",
    "write_dfa_states_json(dfa_states, False)\n",
    "\n",
    "minimized_states_dict = minimize_dfa(dfa_states, set_of_actions)\n",
    "write_dfa_states_json(minimized_states_dict, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62cd17edec06c1bcb7cce561853235234094d242005d116fab77979ddb024dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
